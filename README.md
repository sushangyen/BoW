The goal of the project is to use feature point detection method to localize the users’ position. With 360 camera and stereo images analysis, we have already built up a 3D feature point cloud. Usually, for an indoor metro station, there are more than a million of feature points in the 3D point cloud database. It’s almost impossible to find out the matching result immediately, if we have to try-and-trial million times. Then, how can we effectively get the initial location when user open the app in the station? Here, I use visual Bag-of-Words method (BOW) to do the fast matching prediction.
